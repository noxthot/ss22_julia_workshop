<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
   <link rel="stylesheet" href="/ss22_julia_workshop/libs/katex/katex.min.css">
     
   <link rel="stylesheet" href="/ss22_julia_workshop/libs/highlight/github.min.css">
   
    <script src="/ss22_julia_workshop/libs/clipboard.min.js"></script>
  
  
  <script src="/ss22_julia_workshop/libs/plotly-1_58_5.min.js"></script> 
  <script>
    // This function is used when calling `\fig{...}` See # Using \fig{...} below
    const PlotlyJS_json = async (div, url) => {
      response = await fetch(url); // get file
      fig = await response.json(); // convert it to json
      // Make the plot fit the screen responsively. See the documentation of plotly.js. https://plotly.com/javascript/responsive-fluid-layout/
      if (typeof fig.config === 'undefined') { fig["config"]={} }
      delete fig.layout.width
      delete fig.layout.height
      fig["layout"]["autosize"] = true
      fig["config"]["autosizable"] = true
      fig["config"]["responsive"] = true

      // make it easier to scroll throught the website rather than being blocked by a figure.
      fig.config["scrollZoom"] = false

      // PlotlyJS.savefig by default add the some more attribute to make a static plot.
      // Disable them to make the website fancier.
      delete fig.config.staticPlot
      delete fig.config.displayModeBar
      delete fig.config.doubleClick
      delete fig.config.showTips

      Plotly.newPlot(div, fig);
    };
  </script>
  
  <link rel="stylesheet" href="/ss22_julia_workshop/css/jtd.css">
<link rel="stylesheet" href="/ss22_julia_workshop/css/extras.css">
<link rel="icon" href="/ss22_julia_workshop/assets/favicon.ico">

<style>
  /* #148 wrap long header */
  .franklin-content a.header-anchor,
  .franklin-toc li a
   {
    word-wrap: break-word;
    white-space: normal;
  }
</style>

   <title>Unsupervised Learning</title>  
</head>
<body>                      <!-- closed in foot.html -->
<div class="page-wrap">   <!-- closed in foot.html -->
  <!-- SIDE BAR -->
  <div class="side-bar">
    <div class="header">
      <a href="/ss22_julia_workshop/" class="title">
        Julia
      </a>
    </div>
    <label for="show-menu" class="show-menu">MENU</label>
    <input type="checkbox" id="show-menu" role="button">
    <div class="menu" id="side-menu">
      <ul class="menu-list">
        <li class="menu-list-item "><a href="/ss22_julia_workshop/" class="menu-list-link ">Start</a>
        <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/introduction/" class="menu-list-link ">Introduction</a>
          <ul class="menu-list-child-list ">
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/introduction/basis_datatypes_and_operations" class="menu-list-link ">Basic Data Types and Operations</a>
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/introduction/package_manager" class="menu-list-link ">Package Manager</a>
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/introduction/matrix_vectors" class="menu-list-link ">Matrix and Vector Operations</a>
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/introduction/conditional_evaluations" class="menu-list-link ">Conditional evaluations</a>
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/introduction/loops" class="menu-list-link ">Loops</a>
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/introduction/functions" class="menu-list-link ">Functions</a>
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/introduction/macros" class="menu-list-link ">Macros</a>
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/introduction/worksheet_1" class="menu-list-link ">Worksheet 1</a>
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/introduction/worksheet_2" class="menu-list-link ">Worksheet 2</a>
          </ul>
        <li class="menu-list-item active"><a href="/ss22_julia_workshop/pages/datascience/" class="menu-list-link active">Data Science</a>
          <ul class="menu-list-child-list ">
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/datascience/loading_data" class="menu-list-link ">Loading data</a>
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/datascience/saving_data" class="menu-list-link ">Saving data</a>
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/datascience/exploratory_da" class="menu-list-link ">Exploratory Data Analysis</a>
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/datascience/datasets" class="menu-list-link ">Data Sets</a>
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/datascience/unsupervised_learning" class="menu-list-link active">Unsupervised Learning</a>
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/datascience/supervised_learning" class="menu-list-link ">Supervised Learning</a>
          </ul>
        <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/hpc/" class="menu-list-link ">Parallel computing</a>
          <ul class="menu-list-child-list ">
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/hpc/performance" class="menu-list-link ">Measuring performance</a>
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/hpc/simd" class="menu-list-link ">Single Instruction Multiple Data</a>
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/hpc/pi" class="menu-list-link ">&pi; example</a>
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/hpc/multithreading" class="menu-list-link ">Multithreading</a>
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/hpc/distributed" class="menu-list-link ">Distributed computing</a>
            <li class="menu-list-item "><a href="/ss22_julia_workshop/pages/hpc/gpu" class="menu-list-link ">GPU computing</a>
          </ul>
      </ul>
    </div>
    <div class="footer">
      This is <em>Just the docs</em>, adapted from the <a href="https://github.com/pmarsceill/just-the-docs" target="_blank">Jekyll theme</a>.
    </div>
  </div>
  <!-- CONTENT -->
  <div class="main-content-wrap"> <!-- closed in foot.html -->
    <div class="main-content">    <!-- closed in foot.html -->
      <div class="main-header">
        SS22 Julia Workshop Obergurgl
      </div>



<!-- Content appended here (in class franklin-content) -->
<div class="franklin-content"><h1 id="unsupervised_learning"><a href="#unsupervised_learning" class="header-anchor">Unsupervised Learning</a></h1>
<div class="franklin-toc"><ol><li><a href="#clustering_k_means">Clustering &#40;K Means&#41;</a><ol><li><a href="#theory">Theory</a></li><li><a href="#application">Application</a><ol><li><a href="#mlj_introduction">MLJ introduction</a></li><li><a href="#mlj_application">MLJ application</a></li></ol></li></ol></li><li><a href="#dimensionality_reduction_principal_component_analysis">Dimensionality Reduction &#40;Principal Component Analysis&#41;</a><ol><li><a href="#theory__2">Theory</a></li><li><a href="#application__2">Application</a></li></ol></li><li><a href="#outlook">Outlook</a></li></ol></div>
<p>The term <em>unsupervised learning</em> subsumes all kinds of algorithms that are used to gain insights from such an unlabeled data set. Typically these algorithms fall into three main categories:</p>
<ul>
<li><p><strong>Association rules</strong>: to discover relationships between different variables &#40;e.g. for recommender systems: <em>customers who bought X also bought Y</em>&#41;</p>
</li>
<li><p><strong>Clustering</strong>: for grouping data based on their similarities &#40;e.g. grouping news articles about similar topics&#41;</p>
</li>
<li><p><strong>Dimensionality reduction</strong>: for transforming data from a high-dimensional to a low-dimensional space &#40;e.g. used for denoising images&#41;</p>
</li>
</ul>
<p>In this section we will quickly glimpse into clustering with an algorithm called <em>K means</em>, and into dimensionality reduction by applying PCA &#40;<em>Principal Component Analysis</em>&#41; and UMAP &#40;<em>Uniform Manifold Approximation and Projection</em>&#41;.</p>
<p>Let us imagine that we only have a folder with 10.000 images of various hand written digits without any label and we would like to sort them into ten buckets: One bucket where we only have images of 0s, one bucket where we only have images of 1s and so on. Technically speaking, we are expecting to see ten different digits &#40;<em>categories</em>&#41; and within each category, the similarity between the images is expected to be high. How are we able to tackle this problem? One possibility is to sort them by hand. A less time consuming approach could be to apply some unsupervised learning algorithms.</p>
<p>Here we will work with MNIST&#39;s flattened test data set <code>X_test</code> which we prepared in the previous section. We could also use the training data set or merge both data sets, but <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10.000</mn></mrow><annotation encoding="application/x-tex">10.000</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10.000</span></span></span></span> samples are quite good already and we spare some computation time within the workshop. In practice we would go for the full data set of course.</p>
<p>In case you do not have <code>X_test</code> ready, look at the following code:</p>
<button type="button" class="collapsible" style="background-color:#fffca5"> Solution </button><div class="collapsiblecontent">  </p>
<pre><code class="julia hljs"><span class="hljs-keyword">using</span> MLDatasets

df_test = MNIST(:test)
X_test = reshape(df_test.features, (<span class="hljs-number">28</span> * <span class="hljs-number">28</span>, :))&#x27;</code></pre>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext> </mtext></mrow><annotation encoding="application/x-tex">~</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0em;"></span><span class="mspace nobreak"> </span></span></span></span> </div>
<h2 id="clustering_k_means"><a href="#clustering_k_means" class="header-anchor">Clustering &#40;K Means&#41;</a></h2>
<h3 id="theory"><a href="#theory" class="header-anchor">Theory</a></h3>
<p>The K means algorithm is one of the most popular clustering methods. For a given set of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> observations <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mtext mathvariant="bold">x</mtext><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mtext mathvariant="bold">x</mtext><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\textbf{x}_1, \dots, \textbf{x}_n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord text"><span class="mord textbf">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord text"><span class="mord textbf">x</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, the algorithm strives to partition the observations into <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> sets <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>S</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>S</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(S_1, \ldots, S_k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, such that the inner cluster variance is minimized. Formally, the goal is to find </p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mrow><mi mathvariant="normal">argmin</mi><mo>⁡</mo></mrow><mi>S</mi></msub><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><munder><mo>∑</mo><mrow><mtext mathvariant="bold">x</mtext><mo>∈</mo><msub><mi>S</mi><mi>i</mi></msub></mrow></munder><mi mathvariant="normal">∥</mi><mtext mathvariant="bold">x</mtext><mo>−</mo><msub><mi>μ</mi><mi>i</mi></msub><msup><mi mathvariant="normal">∥</mi><mn>2</mn></msup><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">
\operatorname{argmin}_S \sum_{i=1}^k \sum_{\textbf{x} \in S_i} \|\textbf{x} - \mu_i\|^2,
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.2305em;vertical-align:-1.3944em;"></span><span class="mop"><span class="mop"><span class="mord mathrm">argmin</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2342em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8361em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8557em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord textbf mtight">x</span></span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0576em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">∥</span><span class="mord text"><span class="mord textbf">x</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mpunct">,</span></span></span></span></span>
<p>where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>μ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">{\mu}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">μ</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> denotes the mean of the set <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">S_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</p>
<p>The naive algorithm works iteratively for a given <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>:</p>
<ol>
<li><p>Randomly initialize <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> points <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>μ</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>μ</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">\mu_1, \dots, \mu_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, we call those points <em>cluster centers</em>.</p>
</li>
<li><p>Assign every point to the nearest cluster center <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>μ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mu_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>. These points define the sets <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">S_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</p>
</li>
<li><p>Calculate the mean within each set <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">S_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and replace the previous cluster centers.</p>
</li>
<li><p>Repeat until the cluster centers are stable &#40;with some tolerance&#41;.</p>
</li>
</ol>
<p>The following animation illustrates this process: 
<figure style="text-align:center;">
<img src="/ss22_julia_workshop/assets/pages/datascience/K-means_convergence.gif" style="padding:0; " alt=" K means convergence."/>
<figcaption> K means convergence. Original source: <p style="font-size:11px"><a href=" https://commons.wikimedia.org/wiki/File:K-means_convergence.gif"> https://commons.wikimedia.org/wiki/File:K-means_convergence.gif</a></p></figcaption>
</figure>
</p>
<h3 id="application"><a href="#application" class="header-anchor">Application</a></h3>
<p>Keep in mind that each row of <code>X_test</code> corresponds to one image and consists of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>784</mn></mrow><annotation encoding="application/x-tex">784</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">784</span></span></span></span> values. If we imagine a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>784</mn></mrow><annotation encoding="application/x-tex">784</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">784</span></span></span></span>-dimensional space, we could map a handwritten digit to a single point in that space and when we do this for every image in the test data set, we will end up with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10.000</mn></mrow><annotation encoding="application/x-tex">10.000</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10.000</span></span></span></span> points in a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>784</mn></mrow><annotation encoding="application/x-tex">784</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">784</span></span></span></span>-dimensional space.  Hopefully, images containing the same digit will end up close to each other, because in this case we could successfully cluster them with K means. Since we have ten digits, we expect to find ten clusters and of course we do not have to program that algorithm all by ourselves. </p>
<h4 id="mlj_introduction"><a href="#mlj_introduction" class="header-anchor">MLJ introduction</a></h4>
<p>Julia offers a nice machine learning meta package called <a href="https://github.com/alan-turing-institute/MLJ.jl"><code>MLJ.jl</code></a>, which provides a common interface to over 160 machine learning algorithms. The basic workflow for using an unsupervised model is given by the following steps:</p>
<ol>
<li><p>Loading the data</p>
</li>
<li><p>Loading the model</p>
</li>
<li><p>Instantiating the model</p>
</li>
<li><p>Transforming the data</p>
</li>
<li><p>Instantiating the machine &#40;this is how <code>MLJ.jl</code> calls the object that combines the model with data&#41;</p>
</li>
<li><p>Fitting the machine/model by running <code>fit&#40;&#41;</code> on the machine</p>
</li>
<li><p>Optional: Transforming the data by applying the fitted model</p>
</li>
</ol>
<h4 id="mlj_application"><a href="#mlj_application" class="header-anchor">MLJ application</a></h4>
<p>The code for loading the data and model is straight-forward:</p>
<pre><code class="julia hljs"><span class="hljs-keyword">using</span> DataFrames, MLDatasets, MLJ, ParallelKMeans

<span class="hljs-comment"># Loading the data</span>
df_test = MNIST(:test)
X_test = reshape(df_test.features, (<span class="hljs-number">28</span> * <span class="hljs-number">28</span>, :))&#x27;

<span class="hljs-comment"># Loading the model</span>
KMEANS = <span class="hljs-meta">@load</span> KMeans pkg=ParallelKMeans</code></pre>
<p><code>KMEANS</code> comes with several optional arguments. Unfortunately, <code>MLJ</code> lacks documentation here:</p>
<pre><code class="julia-repl hljs">help?&gt; KMEANS
search: KMEANS kmeans kmeans_model mach_kmeans model_kmeans ParallelKMeans PKGMODE_MANIFEST

  ParallelKMeans model constructed by the user.
  See also the [package documentation](https://pydatablog.github.io/ParallelKMeans.jl/stable).</code></pre>
<p>But simply initializing <code>KMEANS</code> with default arguments and having a look at the package&#39;s <a href="https://pydatablog.github.io/ParallelKMeans.jl/stable">website</a> gives some hints on how to parametrize the model:</p>
<pre><code class="julia-repl hljs"><span class="hljs-meta prompt_">julia&gt;</span><span class="language-julia"> KMEANS()
</span>KMeans(
  algo = Hamerly(), 
  k_init = &quot;k-means++&quot;, 
  k = 3, 
  tol = 1.0e-6, 
  max_iters = 300, 
  copy = true, 
  threads = 1, 
  rng = Random._GLOBAL_RNG(), 
  weights = nothing, 
  init = nothing)</code></pre>
<p>Apparently <code>k</code> corresponds to the number of clusters, so we set this parameter to <code>10</code>:</p>
<pre><code class="julia hljs"><span class="hljs-comment"># initialize the model</span>
model_kmeans = KMEANS(k=<span class="hljs-number">10</span>)</code></pre>
<p>For setting up the machine, we first need to know how to transform our data. <code>MLJ.jl</code> states that in general two-dimensional data is expected to be <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/getting_started/#Two-dimensional-data">tabular</a> and <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/getting_started/#Observations-correspond-to-rows,-not-columns">observations correspond to rows, not columns</a>.  Finally, specific models need specific <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/getting_started/#Inputs">scientific types</a> as input. The second condition is already fulfilled for <code>X_test</code>. The first condition is easily fixed by calling <code>X_test_tab &#61; MLJ.table&#40;X_test&#41;</code> and for the last condition, we need to check whether <code>scitype&#40;X_test_tab&#41;</code> is of type <code>input_scitype&#40;model_kmeans&#41;</code>:</p>
<pre><code class="julia-repl hljs"><span class="hljs-meta prompt_">julia&gt;</span><span class="language-julia"> X_test_tab = MLJ.table(X_test)
</span>Tables.MatrixTable{LinearAlgebra.Adjoint{Float32, Matrix{Float32}}} with 10000 rows, 784 columns, and schema:
 :x1    Float32
 :x2    Float32
 :x3    Float32
 :x4    Float32
 :x5    Float32
 :x6    Float32
 ⋮      
 :x780  Float32
 :x781  Float32
 :x782  Float32
 :x783  Float32
 :x784  Float32

<span class="hljs-meta prompt_">julia&gt;</span><span class="language-julia"> scitype(X_test_tab)
</span>Table{AbstractVector{Continuous}}

<span class="hljs-meta prompt_">julia&gt;</span><span class="language-julia"> input_scitype(model_kmeans)
</span>Table{&lt;:AbstractVector{&lt;:Continuous}}

<span class="hljs-meta prompt_">julia&gt;</span><span class="language-julia"> scitype(X_test_tab) &lt;: input_scitype(model_kmeans)
</span>true</code></pre>
<p>Now we are ready to instantiate the machine and fit the model&#39;s parameters. In this case, transforming the data is not necessary, because we are only interested in the clusters&#39; centers:</p>
<pre><code class="julia hljs"><span class="hljs-comment"># Initializing the machine</span>
mach_kmeans = machine(model_kmeans, X_test_tab)

<span class="hljs-comment"># Fitting the model&#x27;s parameters</span>
fit!(mach_kmeans)</code></pre>
<p>After fitting the model, we hopefully found ten representative cluster centers. With <code>report&#40;mach_kmeans&#41;</code>, we can have a look at the <em>training</em> &#40;fitting&#41; results. </p>
<pre><code class="julia-repl hljs"><span class="hljs-meta prompt_">julia&gt;</span><span class="language-julia"> r_machkmeans = report(mach_kmeans)
</span>(cluster_centers = [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0],
 iterations = 104,
 totalcost = 389412.2314496818,
 assignments = [1, 8, 6, 10, 2, 6, 1, 2, 2, 4  …  1, 9, 1, 10, 6, 5, 8, 4, 4, 3],
 labels = CategoricalArrays.CategoricalValue{Int64, UInt32}[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],)</code></pre>
<p>Please note the format of the cluster centers. We have ten clusters given in ten columns. Each column has <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>28</mn><mo>×</mo><mn>28</mn></mrow><annotation encoding="application/x-tex">28 \times 28</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">28</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">28</span></span></span></span> entries, corresponding to one point in the high dimensional space:</p>
<pre><code class="julia-repl hljs"><span class="hljs-meta prompt_">julia&gt;</span><span class="language-julia"> r_machkmeans.cluster_centers
</span>784×10 Matrix{Float64}:
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 ⋮                        ⋮                   
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0</code></pre>
<p>Each of these points can be reshaped to its 2D representative and visualized. Here we provide the code to plot the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span>-th cluster providing <code>r_machkmeans</code>:</p>
<pre><code class="julia hljs"><span class="hljs-keyword">using</span> StatsPlots; gr()

<span class="hljs-keyword">function</span> plot_clustercenter(report, i)
    cc = report.cluster_centers[:, i]  <span class="hljs-comment"># get one cluster</span>
    cc_reshaped = reshape(cc, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>)    <span class="hljs-comment"># reshape from flat to 2D</span>
    <span class="hljs-keyword">return</span> StatsPlots.plot(convert(<span class="hljs-built_in">Matrix</span>{Gray}, cc_reshaped&#x27;)) <span class="hljs-comment"># Correctly rotate the image, transform to grey and show with StatsPlots</span>
<span class="hljs-keyword">end</span></code></pre>
<p>In our case the ten cluster centers look like this:</p>
<img src="/ss22_julia_workshop/assets/pages/datascience/unsupervised_clusters_kmeans.png" alt="Cluster centers - KMeans">
<p>We can clearly recognize the numbers <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn></mrow><annotation encoding="application/x-tex">6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">6</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn></mrow><annotation encoding="application/x-tex">8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">8</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9</mn></mrow><annotation encoding="application/x-tex">9</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">9</span></span></span></span>, but obviously it is more difficile for numbers <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">4</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn></mrow><annotation encoding="application/x-tex">5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn></mrow><annotation encoding="application/x-tex">7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">7</span></span></span></span>. When looking closely, we see parts of the silhouettes too, but we are of course not completely happy with this fit. We might be able to grasp more of the underlying structure by increasing the number of clusters.</p>
<button type="button" class="collapsible" style="background-color:#b5ddff"> Exercise </button><div class="collapsiblecontent">  Rerun this experiment with 20 clusters centers and evaluate the results. </div>
<h2 id="dimensionality_reduction_principal_component_analysis"><a href="#dimensionality_reduction_principal_component_analysis" class="header-anchor">Dimensionality Reduction &#40;Principal Component Analysis&#41;</a></h2>
<h3 id="theory__2"><a href="#theory__2" class="header-anchor">Theory</a></h3>
<p>Simply speaking, the <em>principal component analysis</em> &#40;PCA&#41; is a technique used for reducing the dimensionality of data while preserving as much of the information that is contained in the original data. PCA does so by projecting the data points onto a lower-dimensional subspace while trying to keep the variance among the data set.</p>
<p>Technically speaking, the <em>principal components</em> are the eigenvectors of the data&#39;s covariance matrix.</p>
<p>The dimension of the original data is then reduced to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> by projecting the data using the first <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> eigenvectors. Please note that the resulting projected data are essentially linear combinations of the original data which capture most of the variance in the original data.</p>
<p>An illustration is shown here:</p>

<figure style="text-align:center;">
<img src="/ss22_julia_workshop/assets/pages/datascience/GaussianScatterPCA.png" style="padding:0; " alt=" Principal Component Analysis"/>
<figcaption> Principal Component Analysis Original source: <p style="font-size:11px"><a href=" https://de.wikipedia.org/wiki/Hauptkomponentenanalyse#/media/Datei:GaussianScatterPCA.svg"> https://de.wikipedia.org/wiki/Hauptkomponentenanalyse#/media/Datei:GaussianScatterPCA.svg</a></p></figcaption>
</figure>

<div class="important">Since PCA is sensitive to the scaling of variables, input data is usually standardized prior application of the algorithm.</div>
<h3 id="application__2"><a href="#application__2" class="header-anchor">Application</a></h3>
<p>Since we decided to use <code>MLJ.jl</code> as a meta package, it would be easy to scale the data and also apply the PCA. For scaling the data we could use the <code>Standardizer&#40;&#41;</code> which is part of MLJs <a href="https://alan-turing-institute.github.io/MLJ.jl/v0.2/built_in_transformers/">built-in transformers</a>.</p>
<p>In case you have a fresh REPL, you can start off with this code:</p>
<button type="button" class="collapsible" style="background-color:#fffca5"> Solution </button><div class="collapsiblecontent">  </p>
<pre><code class="julia hljs"><span class="hljs-keyword">using</span> DataFrames, MLDatasets, MLJ

df_test = MNIST(:test)

X_test = reshape(df_test.features, (<span class="hljs-number">28</span> * <span class="hljs-number">28</span>, :))&#x27;
X_test_tab = MLJ.table(X_test)

y_test = df_test.targets</code></pre>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext> </mtext></mrow><annotation encoding="application/x-tex">~</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0em;"></span><span class="mspace nobreak"> </span></span></span></span> </div>
<p>But in our case standardizing the data leads to various problems:</p>
<ul>
<li><p>Some pixels are always <code>0</code>.</p>
</li>
<li><p>The variance in a few pixels is very low.</p>
</li>
</ul>
<p>And since we are working with &quot;clean&quot; image data, we want to keep every pixel on the same scale, so for convenience reasons we skip the standardizing here.</p>
<button type="button" class="collapsible" style="background-color:#caffa5"> Example </button><div class="collapsiblecontent">  For the sake of completeness we demonstrate how the built-in <code>Standardizer</code> of <code>MLJ</code> can be applied. But unfortunately it scales each of the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>784</mn></mrow><annotation encoding="application/x-tex">784</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">784</span></span></span></span> columns separately which we definately do not want in our case. </p>
<pre><code class="julia hljs"><span class="hljs-comment"># Instantiating the model</span>
standardizer_model = Standardizer()

<span class="hljs-comment"># Instantiating the machine (this is how `MLJ.jl` calls the object that combines the model with data)</span>
mach_standardizer = machine(standardizer_model, X_test_tab)

<span class="hljs-comment"># Fit model (compute mean and std)</span>
fit!(mach_standardizer)

<span class="hljs-comment"># Transform the data by applying the fitted model</span>
X_test_scaled = MLJ.transform(mach_standardizer, X_test_tab)

<span class="hljs-comment"># WARNING - THIS IS HACKY: X_test_scaled unfortunately contains NaNs. We replace them by 0. Therefor we first need to convert it to a data frame.</span>
X_test_scaled = DataFrame(X_test_scaled)
X_test_scaled .= ifelse.(isnan.(X_test_scaled), <span class="hljs-number">0</span>, X_test_scaled)</code></pre>
<p>But one could think of just standardizing over all the columns simultaneously. </div>
<p>We are now ready for applying the principal component analysis in the same fashion:</p>
<pre><code class="julia hljs"><span class="hljs-keyword">using</span> MLJMultivariateStatsInterface

PCA = <span class="hljs-meta">@load</span> PCA pkg=MultivariateStats
pca = PCA()

mach_pca = machine(pca, X_test_tab)
fit!(mach_pca)</code></pre>
<p>In case you get an exception <code>MethodError: no method matching size&#40;::MultivariateStats.PCA&#123;Float64&#125;, ::Int64&#41;</code> when running this code, be sure to add / update <code>MultivariateStats</code> to at least <code>0.9.1</code>. There unfortunately seems to be a bug in <code>0.9.0</code>.</p>
<p>We did not give a target dimension to <code>PCA&#40;&#41;</code> so by default it is using as many dimensions as there are needed to preserve 99&#37; of the variance of the original data &#40;in our case we need 486 components&#41;. Before we look at the principal components, we are interested to check how the number of principal components relate to the explained variance ratios for our data sample. Therefore, we need to access the <code>principalvars</code> &#40;a list of values&#41; and divide by the total explained variance <code>tvar</code>. Both values are accessible in the report:</p>
<pre><code class="julia hljs">r_pca = report(mach_pca)

explained_variance_ratios = r_pca.principalvars / r_pca.tvar</code></pre>
<p>We are interested in the explained variance for the first <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> dimensions, so we need to compute the cumulative sum before plotting it and we are using the <code>PlotlyJS</code> backend for interactivity:</p>
<pre><code class="julia hljs"><span class="hljs-keyword">using</span> StatsPlots; plotlyjs()

StatsPlots.plot(cumsum(explained_variance_ratios, dims=<span class="hljs-number">1</span>))</code></pre>
<div id="fdpzwn" style=""></div>
<script>
graphDiv = document.getElementById("fdpzwn");
plotlyPromise = PlotlyJS_json(graphDiv, '/ss22_julia_workshop/assets/pages/datascience/plot_pca_explained_variance.json');
</script>

<p>We observe that we only explain around 10&#37; of the variance with two dimensions and we need roughly 115 dimensions to explain 80&#37; of the variance. With other words: our projection loses a lot of information, but we still give it a try and visualize the transformed data. Keep in mind that we are projecting 784 dimensions into a two-dimensional space.</p>
<pre><code class="julia hljs">X_test_pca = MLJ.transform(mach_pca, X_test_tab)

<span class="hljs-meta">@df</span> X_test_pca StatsPlots.scatter(:x1, :x2, alpha=<span class="hljs-number">0.5</span>)</code></pre>
<p><code>:x1</code> and <code>:x2</code> are the names of the first two columns &#40;principal components&#41; in <code>X_test_pca</code> and <code>alpha</code> is added for transparency such that we get an idea about the density of the data points.</p>
<div id="fdpvzk" style=""></div>
<script>
graphDiv = document.getElementById("fdpvzk");
plotlyPromise = PlotlyJS_json(graphDiv, '/ss22_julia_workshop/assets/pages/datascience/plot_pca_nocolor.json');
</script>

<p>This might not seem to be very helpful at first, but in this case we actually have labeled data available and to demonstrate the power of PCA, we will use that labels to add ten colors to this plot. Each digit will get its own color in this plot:</p>
<pre><code class="julia hljs"><span class="hljs-meta">@df</span> X_test_pca StatsPlots.scatter(:x1, :x2, group=y_test, alpha=<span class="hljs-number">0.5</span>, palette=:seaborn_bright)</code></pre>
<p><code>y_test</code> contains our labels, <code>group</code> tells <code>StatsPlots</code> to use that labels for coloring and the <code>palette</code> is set to a <a href="https://docs.juliaplots.org/latest/generated/colorschemes/">colormap</a> which distinguishes nicely between ten groups.</p>
<div id="fdpsvg" style=""></div>
<script>
graphDiv = document.getElementById("fdpsvg");
plotlyPromise = PlotlyJS_json(graphDiv, '/ss22_julia_workshop/assets/pages/datascience/plot_pca_color.json');
</script>

<p>By clicking on the different labels, you are able to hide and show them.  We recommend to have a look at pairs of colours. We see for example that there is quite some overlapping in <code>1</code>s and <code>7</code>s but hardly any overlap in <code>1</code>s and <code>0</code>s. So we expect learning algorithms to be easily able to discriminate between <code>1</code>s and <code>0</code>s while probably having a harder time distinguishing between <code>1</code> and <code>7</code>.  But still we have to keep in mind that we lost a lot of information when transforming to two dimensions, so probably we find a better method for our data set.</p>
<button type="button" class="collapsible" style="background-color:#b5ddff"> Exercise </button><div class="collapsiblecontent">  In this exercise we will use a different dimensionality reduction method called <em>Uniform Manifold Approximation and Projection</em> &#40;UMAP&#41;. Down to its core and very simply speaking, UMAP constructs a high dimensional graph representation of the data set and then tries to fit a low-dimensional graph to be structurally as similar as possible. To get a better understanding, there is also a nice <a href="https://pair-code.github.io/understanding-umap/">webpage with interactive explanations</a>. Unfortunately, this method is also not included in <code>MLJ.jl</code>, so we need to load <a href="https://github.com/dillondaudert/UMAP.jl"><code>UMAP.jl</code></a> directly. Follow this steps to get a nice dimensionality reduction with <code>UMAP.jl</code>:</p>
<ol>
<li><p>Add and use <code>UMAP.jl</code></p>
</li>
<li><p><code>UMAP</code> expects a <code>Matrix</code> as input. Luckily we already have that: <code>X_test</code>.</p>
</li>
<li><p>But <code>X_test</code> is stored in row wise fashion &#40;each observation is one row&#41;. <code>UMAP.jl</code> expects a column-major matrix, so we need to transpose the matrix.</p>
</li>
<li><p>Have a look at the manual of <code>umap</code>, apply the function on the transposed matrix and reduce the dimension to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span></span></span></span>. Note that this computation might needs a couple of minutes.</p>
</li>
<li><p>Store the result in <code>X_test_umap_mat</code> and visualize the result with <code>StatsPlots.scatter&#40;X_test_umap_mat&#91;1, :&#93;, X_test_umap_mat&#91;2, :&#93;, group&#61;y_test, alpha&#61;0.3, palette&#61;:seaborn_bright&#41;</code>.</p>
</li>
<li><p>Reuse the code for previous scatter plot but replace the coloring by the results of the K means clustering algorithm <code>r_kmachmeans.assignments</code>.</p>
</li>
<li><p>Compare the two scatter plots &#40;note that the K means results found ten clusters but the naming of the clusters is arbitrary&#41;.</p>
</li>
</ol>
<p><div class="solution"> Solution </div><div class="solutioncollapsible">  </p>
<pre><code class="julia hljs"><span class="hljs-keyword">using</span> UMAP

X_test_umap_mat = umap(<span class="hljs-built_in">Matrix</span>(X_test)&#x27;, <span class="hljs-number">2</span>)

StatsPlots.scatter(X_test_umap_mat[<span class="hljs-number">1</span>, :], X_test_umap_mat[<span class="hljs-number">2</span>, :], group=y_test, alpha=<span class="hljs-number">0.3</span>, palette=:seaborn_bright)

StatsPlots.scatter(X_test_umap_mat[<span class="hljs-number">1</span>, :], X_test_umap_mat[<span class="hljs-number">2</span>, :], group=r_machkmeans.assignments, alpha=<span class="hljs-number">0.3</span>, palette=:seaborn_bright)</code></pre>
<p>Coloured by real labels:</p>
<div id="fdpthc" style=""></div>
<script>
graphDiv = document.getElementById("fdpthc");
plotlyPromise = PlotlyJS_json(graphDiv, '/ss22_julia_workshop/assets/pages/datascience/plot_umap_color.json');
</script>

<p>Coloured by K means assigments: <div id="fdpale" style=""></div>
<script>
graphDiv = document.getElementById("fdpale");
plotlyPromise = PlotlyJS_json(graphDiv, '/ss22_julia_workshop/assets/pages/datascience/plot_umap_colored_by_cluster.json');
</script>
 </div> </div>
<h2 id="outlook"><a href="#outlook" class="header-anchor">Outlook</a></h2>
<p>Sometimes, it might help to combine dimensionality reduction with a clustering algorithm. The previous exercise demonstrates that UMAP manages to separate the data quite nicely, even when going down to two dimensions. Alternatively, we could, for example, first reduce the dimension of the original data set to ten and then apply a clustering algorithm on this lower dimensional data.</p>
<div class="page-foot">
    <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> - <a href="https://ehrensperger.dev/">Gregor Ehrensperger</a>, <a href="https://lfuonline.uibk.ac.at/public/people.vcard?id=59131">Peter Kandolf</a>, <a href="https://lfuonline.uibk.ac.at/public/people.vcard?id=415344">Jonas Kusch</a>. Last modified: July 21, 2022.
    Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
</div>
</div><!-- CONTENT ENDS HERE -->
    </div> <!-- end of class main-content -->
    </div> <!-- end of class main-content-wrap -->
    </div> <!-- end of class page-wrap-->
    
      



    
    
      


      <script>
    (function(){
    
      // Get the elements.
      // - the 'pre' element.
      // - the 'div' with the 'paste-content' id.
    
      var pre = document.getElementsByTagName('pre');
    
      // Add a copy button in the 'pre' element.
      // which only has the className of 'language-'.
    
      for (var i = 0; i < pre.length; i++) {
        var isLanguage = pre[i].children[0].tagName == 'CODE';
    
        if ( isLanguage ) {
          var button           = document.createElement('button');
              button.className = 'copy-button';
              button.textContent = 'Copy';
    
              pre[i].appendChild(button);
        }
      };
    
      // Run Clipboard
    
      var copyCode = new Clipboard('.copy-button', {
        target: function(trigger) {
          return trigger.previousElementSibling;
        }
      });
    
      // On success:
      // - Change the "Copy" text to "Copied".
      // - Swap it to "Copy" in 2s.
      // - Lead user to the "contenteditable" area with Velocity scroll.
    
      copyCode.on('success', function(event) {
        event.clearSelection();
        event.trigger.textContent = 'Copied';
        window.setTimeout(function() {
          event.trigger.textContent = 'Copy';
        }, 2000);
    
      });
    
      // On error (Safari):
      // - Change the  "Press Ctrl+C to copy"
      // - Swap it to "Copy" in 2s.
    
      copyCode.on('error', function(event) {
        event.trigger.textContent = 'Press "Ctrl + C" to copy';
        window.setTimeout(function() {
          event.trigger.textContent = 'Copy';
        }, 5000);
      });
    
    })();
</script>
    
  </body>
</html>

<script>
  var coll = document.getElementsByClassName("collapsible");
  var i;

  for (i = 0; i < coll.length; i++) {
    coll[i].addEventListener("click", function() {
      this.classList.toggle("active");
      var content = this.nextElementSibling;
      if (content.style.display === "block") {
        content.style.display = "none";
      } else {
        content.style.display = "block";
      }
    });
  }
</script>

<script>
  var coll = document.getElementsByClassName("solutioncollapsible");
  const queryString = window.location.search;
  const urlParams = new URLSearchParams(queryString);
  const myVar = urlParams.get('solution')
  if ( myVar == 'true') {
    for (i = 0; i < coll.length; i++) {
      coll[i].style.display = "block";
    }
  }
</script>